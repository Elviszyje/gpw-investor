
# üöÄ Przewodnik Implementacji - Ma≈Ça Produkcja

## üìã PrzeglƒÖd Konfiguracji
**Profil:** small_production
**Opis:** Ma≈Çe firmy, osoby prywatne
**Generowany:** 2025-06-27 00:06:14

## üéØ Ograniczenia i Cele
- **Maksymalne tickery:** 30
- **Maksymalni u≈ºytkownicy:** 10
- **Artyku≈Çy dziennie:** 1000

## ‚öôÔ∏è Konfiguracja Scheduler√≥w
```python
# Interwa≈Çy scrapowania
MULTI_TICKER_INTERVAL = 3  # minuty
NEWS_INTERVAL = 30  # minuty
ESPI_INTERVAL = 1  # godziny
ANALYSIS_INTERVAL = 60  # minuty
```

## üîß Zasoby Systemowe
```python
# Threading i przetwarzanie
MAX_THREADS = 12
SELENIUM_INSTANCES = 2
DB_CONNECTIONS = 10
WORKER_PROCESSES = 1
```

## üõ†Ô∏è Kroki Implementacji

### 1. Aktualizacja Konfiguracji Scheduler√≥w
```bash
# Edytuj tickers_config.json
python -c "
import json
config = {
    'scraping_settings': {
        'interval_minutes': 3,
        'use_selenium': True,
        'headless': True
    }
}
with open('tickers_config.json', 'w') as f:
    json.dump(config, f, indent=2)
"
```

### 2. Konfiguracja Bazy Danych
```python
# Aktualizuj connection pool w workers/
DATABASE_CONFIG = {
    'max_connections': 10,
    'pool_size': 10,
    'pool_timeout': 30
}
```

### 3. Funkcje do W≈ÇƒÖczenia


## üìä Monitoring i Alerty
```bash
# Uruchom monitor wydajno≈õci
python performance_monitor.py

# Sprawd≈∫ metryki
tail -f storage/performance_metrics.json
```

## üö® Krytyczne Metryki do Monitorowania
- **Thready:** Max 12, Alert >80%
- **DB Queries:** Alert >500ms
- **Schedulery:** Alert je≈õli <100% uptime
- **Memory:** Alert >80% RAM

## üîß Troubleshooting

### Problem: Wolne scrapowanie
```bash
# Zwiƒôksz selenium instances
SELENIUM_INSTANCES = 3

# Zmniejsz delay miƒôdzy requestami
SCRAPING_DELAY = 1
```

### Problem: Wysokie CPU
```bash
# Zwiƒôksz interwa≈Çy
MULTI_TICKER_INTERVAL = 4
NEWS_INTERVAL = 45
```

### Problem: B≈Çƒôdy bazy danych
```bash
# Zwiƒôksz connection pool
DB_CONNECTIONS = 15
POOL_TIMEOUT = 60
```

## ‚úÖ Checklist Implementacji
- [ ] Zaktualizowana konfiguracja scheduler√≥w
- [ ] Dostosowane limity zasob√≥w
- [ ] W≈ÇƒÖczone odpowiednie funkcje
- [ ] Skonfigurowany monitoring
- [ ] Przetestowane pod obciƒÖ≈ºeniem
- [ ] Wdro≈ºone alerty
- [ ] Backup i recovery plan

## üìà Kolejne Kroki Optymalizacji

1. Rozwa≈ºenie Redis cache przy >1000 artyku≈Ç√≥w/dzie≈Ñ
2. Separacja proces√≥w przy >20 u≈ºytkownikach
3. Przej≈õcie na 'medium_production' przy >30 ticker√≥w

---
*Konfiguracja wygenerowana automatycznie przez GPW Investor Performance Configurator*
